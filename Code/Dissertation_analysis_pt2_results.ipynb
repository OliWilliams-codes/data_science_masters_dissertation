{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a4c572d"
      },
      "source": [
        "# High-Level Summary of Foul Analysis\n",
        "\n",
        "This notebook performs a comprehensive spatial and statistical analysis of foul events in major European football leagues during the 2015/2016 season, excluding Champions League matches.\n",
        "\n",
        "The analysis includes:\n",
        "\n",
        "- **League-wide Foul Count Comparison:** Using Poisson regression and Holm adjustment to compare the average number of fouls per match across different leagues.\n",
        "- **Horizontal Pitch Symmetry Test:** Employing GLMs and Holm adjustment to test for differences in foul counts between mirrored halves of the pitch within each league.\n",
        "- **Poisson Point Process & Spatial Intensity:** Utilizing Kernel Density Estimation (KDE) to create intensity heatmaps visualizing the spatial distribution of fouls for each league.\n",
        "- **Bandwidth Selection for KDE:** Investigating the effect of different bandwidths on the intensity maps and assessing model performance using techniques like GridSearchCV and Quadrat tests.\n",
        "- **Simulating Match Foul Patterns:** Using the thinning algorithm to simulate typical foul distributions in a single game for each league based on estimated intensity.\n",
        "- **Inter-League Spatial Comparison:** Comparing the spatial distribution of fouls between leagues using intensity ratio surfaces.\n",
        "- **Data-Driven Zoning:** Applying Gaussian Mixture Models (GMM) to identify data-driven zones on the pitch based on foul intensity.\n",
        "- **Zonal Statistical Testing:** Conducting permutation tests with Energy Distance to statistically compare the spatial distribution of fouls between leagues within predefined zones, with p-values adjusted using the Holm method.\n",
        "- **Overall Comparison using Stouffer's Z:** Applying Stouffer's Z method to combine p-values across zones for a combined measure of spatial differences between leagues.\n",
        "\n",
        "Overall, the notebook provides a detailed exploration of where and how frequently fouls occur in different leagues, employing various statistical and spatial analysis techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Package Imports**"
      ],
      "metadata": {
        "id": "6gNpf8ZqdDlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsbombpy\n",
        "!pip install mplsoccer\n",
        "!pip install highlight_text"
      ],
      "metadata": {
        "id": "J6NtzblFHDLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsbombpy as sb\n",
        "from mplsoccer import Pitch\n",
        "from highlight_text import ax_text, fig_text\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.spatial.distance import cdist\n",
        "import matplotlib.patches as patches\n",
        "from scipy.interpolate import RegularGridInterpolator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import chi2\n",
        "from matplotlib.cm import ScalarMappable\n",
        "from matplotlib.colors import Normalize\n",
        "from patsy import dmatrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from matplotlib.cm import ScalarMappable\n",
        "import matplotlib.patches as patches"
      ],
      "metadata": {
        "id": "wy4sZuvAcK9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import data**\n",
        "\n",
        "This section of the notebook imports the necessary data for the analysis. The data is stored in multiple CSV files in Google Drive, each potentially containing event data for different matches or seasons. The files are loaded into pandas DataFrames and then concatenated into a single DataFrame (df_concatenated2) for further processing."
      ],
      "metadata": {
        "id": "PGWOOEpkqJuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# Specify the path where the CSV file is located in your Google Drive\n",
        "file_path1 = f'/content/drive/My Drive/referee_analysis1.csv'\n",
        "file_path2 = f'/content/drive/My Drive/referee_analysis2.csv'\n",
        "file_path3 = f'/content/drive/My Drive/referee_analysis3.csv'\n",
        "file_path4 = f'/content/drive/My Drive/referee_analysis4.csv'\n",
        "file_path5 = f'/content/drive/My Drive/referee_analysis5.csv'\n",
        "file_path6 = f'/content/drive/My Drive/referee_analysis6.csv'\n",
        "file_path7 = f'/content/drive/My Drive/referee_analysis7.csv'\n",
        "file_path8 = f'/content/drive/My Drive/referee_analysis8.csv'\n",
        "file_path9 = f'/content/drive/My Drive/referee_analysis9.csv'\n",
        "file_path10 = f'/content/drive/My Drive/referee_analysis10.csv'\n",
        "file_path11 = f'/content/drive/My Drive/referee_analysis11.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df_imported1 = pd.read_csv(file_path1)\n",
        "df_imported2 = pd.read_csv(file_path2)\n",
        "df_imported3 = pd.read_csv(file_path3)\n",
        "df_imported4 = pd.read_csv(file_path4)\n",
        "df_imported5 = pd.read_csv(file_path5)\n",
        "df_imported6= pd.read_csv(file_path6)\n",
        "df_imported7 = pd.read_csv(file_path7)\n",
        "df_imported8 = pd.read_csv(file_path8)\n",
        "df_imported9 = pd.read_csv(file_path9)\n",
        "df_imported10 = pd.read_csv(file_path10)\n",
        "df_imported11 = pd.read_csv(file_path11)\n"
      ],
      "metadata": {
        "id": "oG5NCVk1v5GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dfs_to_concat = [\n",
        "    df_imported1,\n",
        "    df_imported2,\n",
        "    df_imported3,\n",
        "    df_imported4,\n",
        "    df_imported5,\n",
        "    df_imported6,\n",
        "    df_imported7,\n",
        "    df_imported8,\n",
        "    df_imported9,\n",
        "    df_imported10,\n",
        "    df_imported11\n",
        "]\n",
        "\n",
        "df_concatenated2 = pd.concat(dfs_to_concat, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "EvhEd-iPv52q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**data selection and engineering**\n",
        "\n",
        "This section focuses on selecting the relevant data for the analysis and engineering new features. We filter the concatenated dataset to include only the '2015/2016' season and exclude matches from the 'Europe - Champions League' competition to focus on major domestic leagues. A binary flag `is_foul_committed` is created to easily identify foul events. Additionally, we transform the geospatial coordinates (`x`, `y`) to `x2` and `y2` by pivoting the pitch by 180 degrees. This transformation is useful for analyzing events from a consistent attacking direction, aiding in visualizations and spatial analysis where directionality is important.;\n",
        "\n"
      ],
      "metadata": {
        "id": "xrbTL3SDdRb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ensure selection of correct data"
      ],
      "metadata": {
        "id": "W81p4ptN2zAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016 = df_concatenated2[df_concatenated2['season'] == '2015/2016'].copy()"
      ],
      "metadata": {
        "id": "8EqjfAm6wDLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create flag for foul data"
      ],
      "metadata": {
        "id": "TG7G8FL722NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016['is_foul_committed'] = (df_concatenated2_2015_2016['field'] == 'Foul_Committed').astype(int)"
      ],
      "metadata": {
        "id": "t-tnUKDPwkrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "exclude champions league data"
      ],
      "metadata": {
        "id": "f3LRf4242_Ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016 = df_concatenated2_2015_2016[\n",
        "    (df_concatenated2_2015_2016['competition'] != 'Europe - Champions League')\n",
        "].copy()\n"
      ],
      "metadata": {
        "id": "SdXyc1Fkwmqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pivot data 180 degrees for visualisation purposes"
      ],
      "metadata": {
        "id": "DBz5ZglG3CyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016['x2']=abs(df_concatenated2_2015_2016['x']-120)\n",
        "df_concatenated2_2015_2016['y2']=abs(df_concatenated2_2015_2016['y']-80)"
      ],
      "metadata": {
        "id": "O-l-8u0aCU9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**League foul count comparison by Poisson Regression and Holm Adjustment**\n",
        "\n",
        "This section compares the average number of fouls committed per match across different major European leagues using Poisson regression. Poisson regression is a generalized linear model (GLM) suitable for modeling count data, like the number of fouls in a match, which are non-negative integers. The model estimates the relationship between the league (as a categorical variable) and the log of the expected foul count.\n",
        "\n",
        "The coefficients from the Poisson model represent the change in the log of the expected foul count relative to the reference category (in this case, 'England - Premier League' as it is the first alphabetically). Exponentiating these coefficients gives the rate ratio, which can be interpreted as how many times more or less likely a foul is to occur in a given league compared to the reference league.\n",
        "\n",
        "We also examine the residual deviance and degrees of freedom to check for overdispersion. A ratio significantly greater than 1 suggests that the variance of the foul counts is higher than expected under the Poisson distribution, indicating potential overdispersion. While the Poisson model provides a useful baseline, overdispersion might suggest that a Negative Binomial model could be a better fit.\n",
        "\n",
        "Finally, we perform pairwise comparisons between the leagues and adjust the p-values using the Holm-Bonferroni method. The Holm adjustment is a multiple comparison procedure that controls the family-wise error rate (FWER), reducing the chance of making a Type I error (false positive) when performing multiple hypothesis tests simultaneously. The adjusted p-values provide a more conservative measure of statistical significance for each comparison."
      ],
      "metadata": {
        "id": "UkzsojjZeF3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data for poisson regression test"
      ],
      "metadata": {
        "id": "1-PJhKyN3UM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foul_committed_per_match = df_concatenated2_2015_2016[df_concatenated2_2015_2016['field'] == 'Foul_Committed'].groupby(['match_id', 'competition']).agg(\n",
        "    total_fouls=('is_foul_committed', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "print(foul_committed_per_match.head())\n"
      ],
      "metadata": {
        "id": "PwfGZqynnfWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summarise data for context"
      ],
      "metadata": {
        "id": "BM0jE7Qs3Zo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foul_committed_avg_by_competition = foul_committed_per_match.groupby('competition')['total_fouls'].mean().reset_index()\n",
        "foul_committed_avg_by_competition = foul_committed_avg_by_competition.rename(columns={'total_fouls': 'average_fouls'})\n",
        "\n",
        "print(\"Average Fouls Committed by Competition (2015/2016 Season):\")\n",
        "foul_committed_avg_by_competition"
      ],
      "metadata": {
        "id": "wZd7rh3yngQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run poisson regression"
      ],
      "metadata": {
        "id": "avsj282M3ctF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fit a Poisson regression model\n",
        "poisson_model = smf.glm(formula='total_fouls ~ C(competition)', data=foul_committed_per_match, family=sm.families.Poisson()).fit()\n",
        "\n",
        "\n",
        "# Summary with adjusted standard errors\n",
        "print(poisson_model.summary())"
      ],
      "metadata": {
        "id": "ZCQfDV1ht-_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# To check for overdispersion, you can compare the residual deviance to the degrees of freedom.\n",
        "# If the residual deviance is significantly larger than the degrees of freedom, it suggests overdispersion.\n",
        "\n",
        "# Get the residual deviance and degrees of freedom from the Poisson model summary\n",
        "residual_deviance = poisson_model.deviance\n",
        "degrees_of_freedom = poisson_model.df_resid\n",
        "\n",
        "print(f\"\\nResidual Deviance: {residual_deviance}\")\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
        "\n",
        "# A common rule of thumb is to check the ratio of residual deviance to degrees of freedom.\n",
        "# If this ratio is significantly greater than 1 (e.g., > 1.5 or 2, depending on context),\n",
        "# overdispersion might be present.\n",
        "deviance_ratio = residual_deviance / degrees_of_freedom\n",
        "print(f\"Deviance Ratio (Residual Deviance / Degrees of Freedom): {deviance_ratio:.4f}\")\n",
        "\n",
        "# You can also perform a formal statistical test for overdispersion,\n",
        "# such as the dispersion test from statsmodels.\n",
        "# Note: The dispersion test is often more appropriate for count data models.\n",
        "# If you suspect overdispersion, a Negative Binomial model is a common alternative.\n",
        "\n",
        "# Let's fit a Negative Binomial model to compare\n",
        "try:\n",
        "    negbin_model = smf.glm(formula='total_fouls ~ C(competition)', data=foul_committed_per_match, family=sm.families.NegativeBinomial()).fit()\n",
        "    print(\"\\nNegative Binomial Model Summary:\")\n",
        "    print(negbin_model.summary())\n",
        "\n",
        "    # Compare AIC values as a measure of model fit (lower is generally better)\n",
        "    print(f\"\\nPoisson Model AIC: {poisson_model.aic:.4f}\")\n",
        "    print(f\"Negative Binomial Model AIC: {negbin_model.aic:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not fit Negative Binomial model. Error: {e}\")\n",
        "\n",
        "# Interpretation:\n",
        "# - If the Deviance Ratio is close to 1, the Poisson model might be appropriate.\n",
        "# - If the Deviance Ratio is significantly greater than 1, the Negative Binomial model\n",
        "#   is likely a better fit for the overdispersed count data.\n",
        "# - Compare the AIC values: the model with the lower AIC generally provides a better fit.\n"
      ],
      "metadata": {
        "id": "GnnzwwmxuD8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique levels of the categorical variable\n",
        "levels = foul_committed_per_match['competition'].unique()\n",
        "\n",
        "# Create DataFrame to predict at each level\n",
        "new_data = pd.DataFrame({'competition': levels})\n",
        "new_data['predicted_mean'] = poisson_model.predict(new_data)\n",
        "new_data['linear_predictor'] = poisson_model.predict(new_data, linear=True)"
      ],
      "metadata": {
        "id": "Qa624ro-uHe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get design matrix\n",
        "X = dmatrix(poisson_model.model.data.design_info.builder, new_data)\n",
        "\n",
        "# Variance-covariance matrix of model\n",
        "cov = poisson_model.cov_params()\n",
        "\n",
        "# Standard errors of linear predictions\n",
        "se = np.sqrt(np.diag(np.dot(X, np.dot(cov, X.T))))\n",
        "new_data['se'] = se"
      ],
      "metadata": {
        "id": "ZRgUuvViuK2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "\n",
        "for (i, j) in combinations(range(len(levels)), 2):\n",
        "    comp1 = new_data.iloc[i]\n",
        "    comp2 = new_data.iloc[j]\n",
        "\n",
        "    diff = comp1['linear_predictor'] - comp2['linear_predictor']\n",
        "    se_diff = np.sqrt(comp1['se']**2 + comp2['se']**2)\n",
        "    z = diff / se_diff\n",
        "    p = 2 * (1 - norm.cdf(np.abs(z)))  # <-- Use norm from scipy.stats\n",
        "\n",
        "    results.append({\n",
        "        'comparison': f\"{comp1['competition']} - {comp2['competition']}\",\n",
        "        'mean_diff (log scale)': diff,\n",
        "        'z': z,\n",
        "        'raw_p': p\n",
        "    })"
      ],
      "metadata": {
        "id": "8Lfmzq_4uLfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert the list of results to a DataFrame\n",
        "comp_df = pd.DataFrame(results)\n",
        "\n",
        "# Adjust p-values using Holm correction (strong control of family-wise error rate)\n",
        "comp_df['p_adj'] = multipletests(comp_df['raw_p'], method='holm')[1]\n",
        "\n",
        "# Determine which comparisons are significant after adjustment\n",
        "comp_df['significant'] = comp_df['p_adj'] < 0.05\n",
        "\n",
        "# Optionally, get the ratio of means (back-transformed from log scale)\n",
        "comp_df['rate_ratio'] = np.exp(comp_df['mean_diff (log scale)'])"
      ],
      "metadata": {
        "id": "_2EanHEAuNXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(comp_df[['comparison',\n",
        "               'mean_diff (log scale)',\n",
        "               'rate_ratio',\n",
        "               'z',\n",
        "               'raw_p',\n",
        "               'p_adj',\n",
        "               'significant']])"
      ],
      "metadata": {
        "id": "EprgRV49uPjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp_df[['raw_p', 'p_adj']] = comp_df[['raw_p', 'p_adj']].round(3)\n"
      ],
      "metadata": {
        "id": "VLQqpjtwueKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Select and print the desired columns\n",
        "comp_df[['comparison', 'raw_p', 'p_adj', 'significant']]"
      ],
      "metadata": {
        "id": "V5FhxKo_ufjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Horizontal pitch statisitical test by Poisson regression and holm adjustment**\n",
        "\n",
        "This section investigates whether the spatial distribution of fouls is symmetrical across the horizontal axis of the pitch within each league. To do this, we divide the pitch into mirrored zones and compare the foul counts in these corresponding areas. We create variables like `y_shift` to measure distance from the center line, `zone` to define broad pitch areas (e.g., 'x1_y1', 'x2_y2'), `y_check` to distinguish between the two horizontal halves, and `competition_check` and `zone_pair` to group mirrored zones within each league. The `side` variable labels whether a zone is on the 'original' or 'mirrored' side of the pitch.\n",
        "\n",
        "For each league (`zone_pair`), we fit a Generalized Linear Model (GLM) with a Poisson distribution to test the hypothesis that there is no difference in the expected number of fouls between the 'original' and 'mirrored' sides of the pitch (`total_fouls ~ C(side)`). The coefficient for `C(side)[T.mirrored]` in each model represents the estimated difference in the log of the expected foul count between the mirrored and original sides for that specific league's zone pair.\n",
        "\n",
        "We then calculate p-values for each league's comparison. To account for multiple comparisons across the different league pairs, we apply the Holm adjustment method to the p-values. A significant adjusted p-value indicates a statistically significant difference in the spatial distribution of fouls between the original and mirrored sides for that league's zone pair."
      ],
      "metadata": {
        "id": "E_RxB45ngag6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016['y_shift'] = abs(df_concatenated2_2015_2016['y'] - 0.5 * df_concatenated2_2015_2016['y'].max())\n",
        "df_concatenated2_2015_2016['zone'] = ''\n",
        "\n",
        "# Define the boundaries\n",
        "x_boundaries = [0,  60, 120]\n",
        "y_adj_boundaries = [0, 20, 40] # Using the minimum and maximum possible y_adj as boundaries\n",
        "\n",
        "# Iterate through rows to assign zones\n",
        "for index, row in df_concatenated2_2015_2016.iterrows():\n",
        "    x = row['x']\n",
        "    y_adj = row['y_shift']\n",
        "\n",
        "    # Determine x zone\n",
        "    x_zone = ''\n",
        "    if x <= x_boundaries[1]:\n",
        "        x_zone = 'x1'\n",
        "    else:\n",
        "        x_zone = 'x2'\n",
        "\n",
        "    # Determine y_adj zone\n",
        "    y_adj_zone = ''\n",
        "    if y_adj <= y_adj_boundaries[1]:\n",
        "        y_adj_zone = 'y1'\n",
        "    else:\n",
        "        y_adj_zone = 'y2'\n",
        "\n",
        "\n",
        "    # Combine to create the zone\n",
        "    df_concatenated2_2015_2016.at[index, 'zone'] = f'{x_zone}_{y_adj_zone}'\n",
        "\n",
        "print(df_concatenated2_2015_2016[['x', 'y_shift', 'zone']].head())\n",
        "print(\"\\nValue counts for the new 'zone' field:\")\n",
        "print(df_concatenated2_2015_2016['zone'].value_counts())"
      ],
      "metadata": {
        "id": "my9PSl1yuJja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concatenated2_2015_2016['y_check'] = df_concatenated2_2015_2016['y'].apply(lambda y: 'a' if y < 40 else 'b')\n",
        "foul_zone_per_match = df_concatenated2_2015_2016.groupby(['match_id', 'zone','y_check']).agg(\n",
        "    total_fouls=('is_foul_committed', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "print(foul_zone_per_match.head())"
      ],
      "metadata": {
        "id": "kfMJqiYBuAh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_concatenated2_2015_2016['competition_check'] = ''\n",
        "\n",
        "# Define the zones and corresponding values\n",
        "competition_mapping = {\n",
        "    ('Spain - La Liga', 'a'): 'A',\n",
        "    ('Spain - La Liga', 'b'): 'A*',\n",
        "    ('England - Premier League', 'a'): 'B',\n",
        "    ('England - Premier League', 'b'): 'B*',\n",
        "    ('France - Ligue 1', 'a'): 'C',\n",
        "    ('France - Ligue 1', 'b'): 'C*',\n",
        "    ('Italy - Serie A', 'a'): 'D',\n",
        "    ('Italy - Serie A', 'b'): 'D*',\n",
        "    ('Germany - 1. Bundesliga', 'a'): 'E',\n",
        "    ('Germany - 1. Bundesliga', 'b'): 'E*',\n",
        "}\n",
        "\n",
        "# Apply the mapping to create the 'zone_check' column\n",
        "for index, row in df_concatenated2_2015_2016.iterrows():\n",
        "    competition_key = (row['competition'], row['y_check'])\n",
        "    if competition_key in competition_mapping:\n",
        "        df_concatenated2_2015_2016.at[index, 'competition_check'] = competition_mapping[competition_key]\n",
        "\n",
        "\n",
        "print(df_concatenated2_2015_2016[['competition', 'y_check', 'competition_check']].head())\n",
        "print(\"\\nValue counts for the new 'zone_check' field:\")\n",
        "print(df_concatenated2_2015_2016['competition_check'].value_counts())"
      ],
      "metadata": {
        "id": "KGe4iQ_SuCfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zone_pairs = {\n",
        "    'A': 'A_pair',\n",
        "    'A*': 'A_pair',\n",
        "    'B': 'B_pair',\n",
        "    'B*': 'B_pair',\n",
        "    'C': 'C_pair',\n",
        "    'C*': 'C_pair',\n",
        "    'D': 'D_pair',\n",
        "    'D*': 'D_pair',\n",
        "    'E': 'E_pair',\n",
        "    'E*': 'E_pair'\n",
        "}\n",
        "df_concatenated2_2015_2016['zone_pair'] = df_concatenated2_2015_2016['competition_check'].map(zone_pairs)\n",
        "df_concatenated2_2015_2016['side'] = df_concatenated2_2015_2016['competition_check'].apply(lambda z: 'original' if not z.endswith('*') else 'mirrored')"
      ],
      "metadata": {
        "id": "jAgfcmZiuMAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foul_zone_per_match = df_concatenated2_2015_2016.groupby(['match_id', 'zone_pair','side']).agg(\n",
        "    total_fouls=('is_foul_committed', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "print(foul_zone_per_match.head())"
      ],
      "metadata": {
        "id": "DU-AdkPTuScD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = []\n",
        "foul_zone_per_match['side'] = pd.Categorical(foul_zone_per_match['side'], categories=['original', 'mirrored'])\n",
        "for pair in foul_zone_per_match['zone_pair'].unique():\n",
        "    subset = foul_zone_per_match[foul_zone_per_match['zone_pair'] == pair]\n",
        "\n",
        "    if subset['side'].nunique() < 2:\n",
        "        continue  # skip if no paired data\n",
        "\n",
        "    model = smf.glm(\n",
        "        formula='total_fouls ~ C(side)',\n",
        "        data=subset,\n",
        "        family=sm.families.Poisson()\n",
        "    ).fit()\n",
        "\n",
        "    coef = model.params['C(side)[T.mirrored]']\n",
        "    se = model.bse['C(side)[T.mirrored]']\n",
        "    z = coef / se\n",
        "    p = 2 * (1 - norm.cdf(np.abs(z)))  # <-- Use norm from scipy.stats\n",
        "\n",
        "    results.append({\n",
        "        'zone_pair': pair,\n",
        "        'coef_diff_log': coef,\n",
        "        'z': z,\n",
        "        'p': p\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Optionally apply FDR correction\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "results_df['adjusted_p'] = multipletests(results_df['p'], method='holm')[1]\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "QaOHmLpUuS1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_deviance = model.deviance\n",
        "degrees_of_freedom = model.df_resid\n",
        "print(f\"\\nResidual Deviance: {residual_deviance}\")\n",
        "print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
        "deviance_ratio = residual_deviance / degrees_of_freedom\n",
        "print(f\"Deviance Ratio (Residual Deviance / Degrees of Freedom): {deviance_ratio:.4f}\")"
      ],
      "metadata": {
        "id": "dDQ6K_0RDflR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Poisson Point Process**\n",
        "\n",
        "This transforms our data using the geospatial x,y coordinates found in data into an intensity heatmap\n",
        "\n",
        "A Poisson Point Process is a mathematical model used to describe the random distribution of points in space or time. In this context, we are using it to model the locations of fouls on the football pitch as points in a 2D spatial area. The intensity heatmap represents the estimated rate or density of fouls across the pitch, where higher intensity indicates areas where fouls are more likely to occur. Kernel Density Estimation (KDE) is a non-parametric technique used here to estimate this continuous intensity function from the discrete foul event locations."
      ],
      "metadata": {
        "id": "jMOSGEnAiahV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Investigating lambdas**\n",
        "Finding the balance point between the best performing modelled lambda and one that makes visual sense\n",
        "\n",
        "This section explores the effect of the bandwidth parameter (often denoted as $\\lambda$ or $h$) in Kernel Density Estimation (KDE) on the resulting foul intensity maps. The bandwidth is a crucial parameter that controls the smoothness of the estimated density function. A smaller bandwidth results in a more localized and potentially noisy estimate that captures fine-grained variations, while a larger bandwidth produces a smoother, more generalized estimate that might obscure local patterns. The goal here is to investigate how different bandwidths influence the appearance of the foul intensity map and consider what bandwidth provides a good balance between capturing spatial patterns and visual interpretability, potentially guided by methods like cross-validation (as explored later)."
      ],
      "metadata": {
        "id": "PzPvdLCdjXdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**visualising different lambdas**\n",
        "\n",
        "Here we test different lambdas on the Spanish - La Liga data\n",
        "\n",
        "This visualization demonstrates the impact of varying the bandwidth parameter on the estimated foul intensity map for Spain - La Liga. By comparing the heatmaps generated with different bandwidths (e.g., 1, 2, 3, 5, 7.5, 10), we can observe how the level of detail and smoothness changes. A very small bandwidth (e.g., 1) shows individual foul clusters more distinctly but can appear noisy. As the bandwidth increases, the heatmap becomes smoother, revealing broader areas of high and low intensity. This visual exploration, along with quantitative measures (like those from GridSearchCV), helps in selecting an appropriate bandwidth for further analysis that best represents the underlying spatial distribution of fouls."
      ],
      "metadata": {
        "id": "t3HTGUuCkLAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_fouls_spain = df_concatenated2_2015_2016[\n",
        "    (df_concatenated2_2015_2016['is_foul_committed'] == 1) &\n",
        "    (df_concatenated2_2015_2016['competition'] == 'Spain - La Liga')\n",
        "].copy()\n",
        "\n",
        "geospatial_features = ['x2', 'y2']\n",
        "\n",
        "# Create a Pitch object for plotting\n",
        "pitch = Pitch(pitch_type='statsbomb', pitch_color='grass', line_color='white', stripe=True)\n",
        "\n",
        "# Define bandwidths for KDE\n",
        "bandwidths = [1, 2, 3, 5, 7.5, 10]\n",
        "\n",
        "# Create a figure with a 2x3 grid of subplots\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
        "\n",
        "# Flatten the axes array for easier iteration\n",
        "ax = ax.flatten()\n",
        "\n",
        "# Loop through each bandwidth and plot on a new subplot\n",
        "for i, h in enumerate(bandwidths):\n",
        "    current_ax = ax[i]\n",
        "\n",
        "    # Draw the pitch on the current subplot\n",
        "    pitch.draw(ax=current_ax)\n",
        "\n",
        "    # Get coordinates for KDE\n",
        "    coords = df_fouls_spain[geospatial_features].values\n",
        "    N_obs = len(coords)\n",
        "    # Create a grid to evaluate the KDE on\n",
        "    X_grid, Y_grid = np.meshgrid(np.linspace(0, 120, 240), np.linspace(0, 80, 160))\n",
        "    grid_coords = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
        "\n",
        "    # Fit KDE model and get intensity\n",
        "    kde = KernelDensity(kernel='gaussian', bandwidth=h)\n",
        "    kde.fit(coords)\n",
        "    log_dens = kde.score_samples(grid_coords)\n",
        "    pdf = np.exp(log_dens).reshape(X_grid.shape)\n",
        "            # === Convert density to intensity ===\n",
        "    lambda_hat = N_obs * pdf\n",
        "    # Plot the heatmap\n",
        "    pcm = current_ax.imshow(lambda_hat, origin='lower', extent=(0, 120, 0, 80),\n",
        "                            cmap='viridis', aspect='auto', alpha=0.8)\n",
        "\n",
        "    # Add a colorbar for the current subplot\n",
        "    fig.colorbar(pcm, ax=current_ax, label='Estimated Foul Intensity', shrink=0.7)\n",
        "\n",
        "    # Add a title for the current subplot, including the bandwidth\n",
        "    current_ax.set_title(f'Foul Intensity Map (BW={h})')\n",
        "\n",
        "# Set a main title for the entire figure\n",
        "fig.suptitle('Effect of Bandwidth on Foul Intensity Map for Spain - La Liga', fontsize=18)\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B0UMDLuPEEFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**performance deteration**\n",
        "\n",
        "Looking at the overall model performance consideration different lambdas for all foul data"
      ],
      "metadata": {
        "id": "IeypzITRkacn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter fouls for 2015/2016 season\n",
        "df_fouls = df_concatenated2_2015_2016[df_concatenated2_2015_2016['is_foul_committed'] == 1].copy()\n",
        "geospatial_features = ['x2', 'y2']\n",
        "unique_competitions = df_fouls['competition'].unique()\n",
        "\n",
        "# Create Pitch object once\n",
        "pitch = Pitch(pitch_color='grass', line_color='white', stripe=True)\n",
        "bandwidths = np.linspace(0.1, 10.0, 30)\n",
        "# Dictionary to store intensity data and best bandwidth per competition\n",
        "competition_intensity_data = {}\n",
        "competition_best_bandwidth = {}\n",
        "coords1 = df_fouls[geospatial_features].values\n",
        "# Define bandwidth search range\n",
        "grid = GridSearchCV(\n",
        "    KernelDensity(kernel='gaussian'),\n",
        "    {'bandwidth': bandwidths},\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid.fit(coords1)\n",
        "\n",
        "# Print tested bandwidths and their mean cross-validation scores\n",
        "\n",
        "for mean_score, std_score, bw in zip(grid.cv_results_['mean_test_score'],\n",
        "                                     grid.cv_results_['std_test_score'],\n",
        "                                     grid.cv_results_['param_bandwidth']):\n",
        "    print(f\"  Bandwidth: {bw:.2f}, Score: {mean_score:.4f} ± {std_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "wylCLGyiNpln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quadrat test**\n",
        "\n",
        "testing to see how the model performs in different areas of the pitch with an 80/20 test train split. N.B. ideally this would be split more carefully but we only need a general sense in this case\n",
        "\n",
        "This section performs a Quadrat test to evaluate how well the estimated intensity map (derived from Kernel Density Estimation) fits the observed foul locations across different areas of the pitch. The pitch is divided into a grid of quadrats, and the observed number of fouls in each quadrat is compared to the expected number of fouls based on the estimated intensity function.\n",
        "\n",
        "To provide a more robust evaluation, a train-test split is applied to the foul data. The Kernel Density Estimation model is fitted only on the training data, and the observed foul counts for the Quadrat test are calculated from the independent test data. This approach helps to assess the model's ability to generalize and predict foul locations on unseen data. The chi-squared statistic and its corresponding p-value from the Quadrat test indicate whether there is a statistically significant difference between the observed and expected foul distributions, suggesting a potential lack of fit of the estimated intensity map."
      ],
      "metadata": {
        "id": "Bs4dwcHpkrmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Filter foul events ===\n",
        "df_fouls = df_concatenated2_2015_2016[df_concatenated2_2015_2016['is_foul_committed'] == 1].copy()\n",
        "\n",
        "unique_competitions = df_fouls['competition'].unique()\n",
        "\n",
        "# Pitch setup (assuming you have mplsoccer installed)\n",
        "pitch = Pitch(pitch_color='grass', line_color='white', stripe=True)\n",
        "\n",
        "# Define the bandwidths to test\n",
        "test_bandwidths = [1, 2, 3, 4, 5]\n",
        "\n",
        "# List to store results for all competitions and bandwidths\n",
        "quadrat_test_results = []\n",
        "\n",
        "for competition in unique_competitions:\n",
        "    print(f\"\\nProcessing data for: {competition}\")\n",
        "    df_comp_fouls = df_fouls[df_fouls['competition'] == competition].copy()\n",
        "\n",
        "    # Extract coordinates for the current competition (full dataset)\n",
        "    coords_full = df_comp_fouls[['x2', 'y2']].values\n",
        "    N_obs_full = len(coords_full) # Total number of fouls for this competition\n",
        "\n",
        "    if N_obs_full < 2:\n",
        "        print(\"Not enough data for KDE and Quadrat Test. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # --- Perform train-test split ---\n",
        "    # Standard 80% training / 20% test split.\n",
        "    # 'random_state' ensures reproducibility of the split.\n",
        "\n",
        "    coords_train, coords_test = train_test_split(coords_full, test_size=0.2, random_state=42)\n",
        "    N_obs_train = len(coords_train)\n",
        "    N_obs_test = len(coords_test)\n",
        "\n",
        "    if N_obs_train < 2 or N_obs_test < 2:\n",
        "        print(f\"Not enough data in train/test sets after split for {competition}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for bandwidth in test_bandwidths:\n",
        "        print(f\"  Testing Bandwidth: {bandwidth}\")\n",
        "\n",
        "        # === KDE fit (ONLY on training data) ===\n",
        "        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
        "        kde.fit(coords_train) # <--- KDE fitted on training data only\n",
        "\n",
        "        # Grid for evaluating the intensity function (full pitch)\n",
        "        X_grid, Y_grid = np.meshgrid(np.linspace(0, 120, 240), np.linspace(0, 80, 160))\n",
        "        grid_coords = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
        "\n",
        "        log_dens = kde.score_samples(grid_coords)\n",
        "        pdf = np.exp(log_dens).reshape(X_grid.shape)\n",
        "\n",
        "        # === Convert density to intensity ===\n",
        "        # lambda_hat represents the estimated intensity function .\n",
        "        lambda_hat = N_obs_full * pdf\n",
        "\n",
        "        # === Quadrat test (using the TEST data for observed counts) ===\n",
        "        nx, ny = 6, 4 # Number of quadrats (rows, columns)\n",
        "        x_edges = np.linspace(0, 120, nx+1)\n",
        "        y_edges = np.linspace(0, 80, ny+1)\n",
        "\n",
        "        # **Observed counts** are now calculated from the **TEST set**\n",
        "        obs_counts = np.zeros((ny, nx), dtype=int)\n",
        "        for i in range(nx):\n",
        "            for j in range(ny):\n",
        "                in_tile = (\n",
        "                    (coords_test[:,0] >= x_edges[i]) & (coords_test[:,0] < x_edges[i+1]) &\n",
        "                    (coords_test[:,1] >= y_edges[j]) & (coords_test[:,1] < y_edges[j+1])\n",
        "                )\n",
        "                obs_counts[j, i] = in_tile.sum()\n",
        "\n",
        "        # **Expected counts** are derived from the `lambda_hat` (which was fitted on training data\n",
        "        # but represents the intensity over the full domain).\n",
        "        exp_counts = np.zeros_like(obs_counts, dtype=float)\n",
        "        dx_fine_grid = 120 / (X_grid.shape[1] - 1)\n",
        "        dy_fine_grid = 80 / (Y_grid.shape[0] - 1)\n",
        "        cell_area_fine_grid = dx_fine_grid * dy_fine_grid\n",
        "\n",
        "        for i in range(nx):\n",
        "            for j in range(ny):\n",
        "                mask = (\n",
        "                    (X_grid >= x_edges[i]) & (X_grid < x_edges[i+1]) &\n",
        "                    (Y_grid >= y_edges[j]) & (Y_grid < y_edges[j+1])\n",
        "                )\n",
        "                # Summing lambda_hat over the quadrat area gives the expected rate for that area.\n",
        "                exp_counts[j, i] = np.sum(lambda_hat[mask]) * cell_area_fine_grid\n",
        "\n",
        "        # IMPORTANT: Scale expected counts to the size of the test set for a direct comparison\n",
        "        # with 'obs_counts' (which came from the test set). The sum of 'exp_counts' (from lambda_hat)\n",
        "        # would sum to N_obs_full. We need to scale it down proportionally to N_obs_test.\n",
        "        scale_factor = N_obs_test / N_obs_full\n",
        "        exp_counts_scaled = exp_counts * scale_factor\n",
        "\n",
        "        valid = exp_counts_scaled > 1e-6 # Filter quadrats with extremely small expected counts (now based on scaled exp_counts)\n",
        "\n",
        "        # Handle cases where no valid quadrats or degrees of freedom are not positive\n",
        "        if valid.sum() <= 1: # Need at least 2 valid quadrats for df > 0 for chi-squared test\n",
        "            chi2_stat, df, p_val = np.nan, np.nan, np.nan\n",
        "            print(f\"  Quadrat Test Skipped (BW={bandwidth}): Not enough valid quadrats for calculation or df <= 0.\")\n",
        "        else:\n",
        "            chi2_stat = np.sum((obs_counts[valid] - exp_counts_scaled[valid])**2 / exp_counts_scaled[valid])\n",
        "            df = valid.sum() - 1 # Degrees of freedom: num valid quadrats - 1 (for estimated total count from scaled data)\n",
        "            p_val = chi2.sf(chi2_stat, df)\n",
        "            print(f\"  Quadrat chi2 = {chi2_stat:.2f}, df={df}, p={p_val:.3f}\")\n",
        "\n",
        "        # Store results\n",
        "        quadrat_test_results.append({\n",
        "            'competition': competition,\n",
        "            'bandwidth': bandwidth,\n",
        "            'chi2_stat': chi2_stat,\n",
        "            'p_value': p_val\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame and print\n",
        "df_quadrat_results = pd.DataFrame(quadrat_test_results)\n",
        "print(\"\\n--- Summary of Quadrat Test Results (Train/Test Split) ---\")\n",
        "print(df_quadrat_results)\n"
      ],
      "metadata": {
        "id": "7HuWkIzrm1gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Foul intensity by league**\n",
        "\n",
        "creating the intensity maps for each league using chosen bandwidth of 3"
      ],
      "metadata": {
        "id": "btK0c8ZulSyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Filter foul events ===\n",
        "df_fouls = df_concatenated2_2015_2016[df_concatenated2_2015_2016['is_foul_committed'] == 1].copy()\n",
        "\n",
        "unique_competitions = df_fouls['competition'].unique()\n",
        "\n",
        "pitch = Pitch(pitch_color='grass', line_color='white', stripe=True)\n",
        "\n",
        "# Dictionary to store intensity data for each competition\n",
        "competition_intensity_data = {}\n",
        "\n",
        "# Define the bandwidths to test\n",
        "test_bandwidths = [3]\n",
        "# List to store results for all competitions and bandwidths\n",
        "quadrat_test_results = []\n",
        "\n",
        "# Determine the number of rows and columns for the 2x3 formation\n",
        "n_rows = 2\n",
        "n_cols = 3\n",
        "\n",
        "# Create subplots for each competition\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6))\n",
        "axes = axes.flatten() # Flatten the axes array for easy iteration\n",
        "for i, competition in enumerate(unique_competitions):\n",
        "#for competition in unique_competitions:\n",
        "    print(f\"\\nProcessing data for: {competition}\")\n",
        "    df_comp_fouls = df_fouls[df_fouls['competition'] == competition].copy()\n",
        "    coords = df_comp_fouls[['x2', 'y2']].values\n",
        "    N_obs = len(coords)\n",
        "\n",
        "    if N_obs < 2:\n",
        "        print(\"Not enough data for KDE and Quadrat Test. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for bandwidth in test_bandwidths:\n",
        "        print(f\"  Testing Bandwidth: {bandwidth}\")\n",
        "\n",
        "        # === KDE fit ===\n",
        "        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth) # Bandwidth changes here\n",
        "        kde.fit(coords)\n",
        "\n",
        "        # Grid for evaluation (consistent resolution)\n",
        "        X_grid, Y_grid = np.meshgrid(np.linspace(0, 120, 240), np.linspace(0, 80, 160))\n",
        "        grid_coords = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
        "\n",
        "        log_dens = kde.score_samples(grid_coords)\n",
        "        pdf = np.exp(log_dens).reshape(X_grid.shape)\n",
        "\n",
        "        # === Convert density to intensity ===\n",
        "        lambda_hat = N_obs * pdf\n",
        "        competition_intensity_data[competition] = lambda_hat\n",
        "        # === Plot intensity map (optional, uncomment if you want to see each plot) ===\n",
        "        ax = axes[i]\n",
        "        pitch.draw(ax=ax)\n",
        "        pcm = ax.imshow(lambda_hat, origin='lower', extent=(0, 120, 0, 80),\n",
        "                        cmap='viridis', aspect='auto', alpha=0.8)\n",
        "        pitch.arrows(0, 0, 0, 0, width=3, headwidth=8, headlength=5,\n",
        "                     color='#e21017', ax=ax, zorder=2, label=\"attacking direction\")\n",
        "        fig.colorbar(pcm, ax=ax, label='Estimated Foul Intensity (λ̂)')\n",
        "        ax.set_title(f'Foul Intensity Map for {competition}')\n",
        "\n",
        "        ax.legend(bbox_to_anchor=(0.5, -0.1),facecolor='white', handlelength=5, edgecolor='None', fontsize=10, loc='upper center') # Adjusted fontsize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "fig.suptitle('Estimated Foul Intensity by League (2015/2016 Season)', y=1.02, fontsize=16) # Add a main title\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bBE0tgYspycd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**simulating a game**\n",
        "\n",
        "Use the thinning algorithm to simulates how a distribution of fouls might look in a game\n",
        "\n",
        "This section utilizes the estimated foul intensity maps and the thinning algorithm to simulate the spatial distribution of fouls in a single \"normal\" game for each league. The thinning algorithm is a method for generating points from a non-homogeneous Poisson Point Process given an estimated intensity function.\n",
        "\n",
        "The key idea here is to scale the overall intensity function (derived from all fouls in the season) so that its integral over the pitch area equals the average number of fouls observed per game in that specific league. By applying the thinning algorithm with this scaled intensity, we can generate a simulated set of foul locations that represents a plausible spatial pattern for a typical match in that competition, based on the observed season-long distribution and average foul rate."
      ],
      "metadata": {
        "id": "y8rzjnn2l3uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df_fouls.groupby('competition').agg(\n",
        "    total_rows=('match_id', 'size'),\n",
        "    unique_match_ids=('match_id', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "summary['average']= summary['total_rows']/summary['unique_match_ids']"
      ],
      "metadata": {
        "id": "-bBzilbYjBLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Filter foul events ===\n",
        "df_fouls = df_concatenated2_2015_2016[df_concatenated2_2015_2016['is_foul_committed'] == 1].copy()\n",
        "unique_competitions = df_fouls['competition'].unique()\n",
        "\n",
        "# Pitch setup\n",
        "pitch = Pitch(pitch_color='grass', line_color='white', stripe=True)\n",
        "\n",
        "# Define the bandwidths to test\n",
        "test_bandwidths = [3]\n",
        "# Create a figure with a 2x3 grid of subplots\n",
        "fig, ax = plt.subplots(2, 3, figsize=(15, 6))\n",
        "axes = ax.flatten()\n",
        "# List to store results for all competitions and bandwidths\n",
        "quadrat_test_results = []\n",
        "for i, competition in enumerate(unique_competitions):\n",
        "    current_ax = axes[i]\n",
        "    #print(f\"\\nProcessing data for: {competition}\")\n",
        "    df_comp_fouls = df_fouls[df_fouls['competition'] == competition].copy()\n",
        "\n",
        "    coords_full = df_comp_fouls[['x2', 'y2']].values\n",
        "    N_obs_full = len(coords_full)\n",
        "\n",
        "    foul_df=summary[summary['competition'] == competition].copy()\n",
        "    average_fouls_per_game_assumption = foul_df['average'].iloc[0]\n",
        "\n",
        "    for bandwidth in test_bandwidths:\n",
        "        #print(f\"  Testing Bandwidth: {bandwidth}\")\n",
        "\n",
        "        # KDE fit\n",
        "        kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
        "\n",
        "        kde.fit(coords_full)\n",
        "\n",
        "        # Grid for evaluation (consistent resolution)\n",
        "        X_grid, Y_grid = np.meshgrid(np.linspace(0, 120, 240), np.linspace(0, 80, 160))\n",
        "        grid_coords = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
        "\n",
        "        log_dens = kde.score_samples(grid_coords)\n",
        "        pdf = np.exp(log_dens).reshape(X_grid.shape)\n",
        "\n",
        "        # === Convert density to intensity for the FULL dataset ===\n",
        "        # This lambda_hat represents the overall spatial intensity for the entire period.\n",
        "        lambda_hat_full_data = N_obs_full * pdf\n",
        "\n",
        "        # === NHPPP simulation for a \"normal game\" ===\n",
        "        # Step 1: Scale the intensity function so its integral represents the average fouls in ONE game.\n",
        "        # This is the key change for simulating a \"normal game\".\n",
        "        # The scale factor applies to the lambda_hat_full_data so that its integral (sum over pitch area)\n",
        "        # will equal 'average_fouls_per_game_assumption'.\n",
        "        lambda_hat_game_scaled = (average_fouls_per_game_assumption / N_obs_full) * lambda_hat_full_data\n",
        "\n",
        "        # Step 2: Set up the interpolator using the game-scaled intensity\n",
        "        interp_game = RegularGridInterpolator(\n",
        "            (np.linspace(0, 120, 240), np.linspace(0, 80, 160)),\n",
        "            lambda_hat_game_scaled.T, # Use the game-scaled intensity here\n",
        "            bounds_error=False,\n",
        "            fill_value=0.0\n",
        "        )\n",
        "\n",
        "        # Step 3: Perform thinning using the game-scaled intensity\n",
        "        A = 120 * 80 # Total area of the pitch\n",
        "        lambda_max_game_scaled = np.max(lambda_hat_game_scaled) # Max intensity from the game-scaled lambda_hat\n",
        "\n",
        "        # N_max is now based on the max intensity of the game-scaled lambda_hat.\n",
        "        # This will result in an average number of simulated points equal to 'average_fouls_per_game_assumption'.\n",
        "        N_max_game_sim = np.random.poisson(lam=lambda_max_game_scaled * A)\n",
        "\n",
        "        U_x = np.random.uniform(0, 120, size=N_max_game_sim)\n",
        "        U_y = np.random.uniform(0, 80, size=N_max_game_sim)\n",
        "        candidates = np.column_stack([U_x, U_y])\n",
        "\n",
        "        lam_vals = interp_game(candidates) # Get intensities at candidate points from game-scaled interpolator\n",
        "\n",
        "        keep = np.random.uniform(0, 1, size=N_max_game_sim) < (lam_vals / lambda_max_game_scaled)\n",
        "        sim_points = candidates[keep]\n",
        "\n",
        "        # === Plot the simulated \"normal game\" ===\n",
        "        pitch.draw(ax=current_ax)\n",
        "        current_ax.scatter(sim_points[:,0], sim_points[:,1], s=6, alpha=0.7, color='red')\n",
        "        # Display the actual number of simulated points\n",
        "        current_ax.set_title(f'Simulated Foul Pattern for a Normal {competition} Game', fontsize=8)\n",
        "\n",
        "\n",
        "\n",
        "# Convert results to DataFrame and print\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "fig.suptitle('Simulated Foul Pattern for a Normal Game', y=1.02, fontsize=16) # Add a main title\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VD1egLuLuOt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing leagues**\n",
        "\n",
        "Take intensity data and compare the ratio across the 2d surface"
      ],
      "metadata": {
        "id": "P2fg3GDLn5ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Take intensity data\n",
        "competitions_to_plot = [comp for comp, intensity in competition_intensity_data.items() if intensity is not None]\n",
        "competitions_with_data = [(comp, data) for comp, data in competition_intensity_data.items() if data is not None]\n",
        "if len(competitions_with_data) >= 2:\n",
        "    # First pass: collect all ratio surfaces to find global vmin and vmax\n",
        "    ratio_surfaces = []\n",
        "    pairs = []\n",
        "    epsilon = 1e-15\n",
        "\n",
        "    for (comp1_name, lambda1), (comp2_name, lambda2) in combinations(competitions_with_data, 2):\n",
        "        if lambda1.shape == lambda2.shape:\n",
        "            ratio_surface = lambda1 / (lambda2 + epsilon)\n",
        "            ratio_surfaces.append(ratio_surface)\n",
        "            pairs.append((comp1_name, comp2_name))\n",
        "        else:\n",
        "            print(f\"Intensity maps for {comp1_name} and {comp2_name} have different shapes. Skipping.\")\n",
        "\n",
        "    # Find global min and max for the ratio plots\n",
        "    global_vmin = min(rs.min() for rs in ratio_surfaces)\n",
        "    global_vmax = max(rs.max() for rs in ratio_surfaces)\n",
        "\n",
        "    # limit the range to something reasonable\n",
        "    global_vmin = max(global_vmin, 0.5)\n",
        "    global_vmax = min(global_vmax, 1.5)\n",
        "\n",
        "    # Generate all combinations of two competitions with data\n",
        "    combinations_to_plot = list(combinations(competitions_with_data, 2))\n",
        "\n",
        "    # Define the layout of the subplots (5 rows, 2 columns)\n",
        "    n_rows = 5\n",
        "    n_cols = 2\n",
        "    plots_per_figure = n_rows * n_cols\n",
        "\n",
        "    # Calculate the total number of figures needed\n",
        "    n_figures = (len(combinations_to_plot) + plots_per_figure - 1) // plots_per_figure\n",
        "\n",
        "    # Iterate through the combinations in chunks and create figures\n",
        "    combo_index = 0\n",
        "    for fig_num in range(n_figures):\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 20),\n",
        "                                 constrained_layout=False)\n",
        "        axes = axes.flatten()\n",
        "        pitch = Pitch(pitch_color='grass', line_color='white', stripe=True)\n",
        "\n",
        "        for i in range(plots_per_figure):\n",
        "            if combo_index < len(combinations_to_plot):\n",
        "                (comp1_name, lambda1), (comp2_name, lambda2) = combinations_to_plot[combo_index]\n",
        "                ax = axes[i]\n",
        "\n",
        "                # Ensure both intensity maps have the same shape before plotting\n",
        "                if lambda1.shape == lambda2.shape:\n",
        "                    # Calculate the ratio surface\n",
        "                    epsilon = 1e-15  # Small value to prevent division by zero\n",
        "                    ratio_surface = lambda1 / (lambda2 + epsilon)\n",
        "\n",
        "                    # Plot Ratio Surface\n",
        "                    pitch.draw(ax=ax)\n",
        "                    pcm = ax.imshow(ratio_surface, origin='lower', extent=(0, 120, 0, 80),\n",
        "                    cmap='mako', aspect='auto', alpha=0.8,vmin=global_vmin, vmax=global_vmax) # Using viridis for ratio\n",
        "                    pitch.arrows(0, 0,0, 0, width=3,headwidth=8, headlength=5, color='#e21017', ax=ax, zorder=2, label = \"attacking direction\")\n",
        "\n",
        "                    ax.legend(bbox_to_anchor=(0.5, -0.1),facecolor='white', handlelength=5, edgecolor='None', fontsize=10, loc='upper center')\n",
        "                    fig.colorbar(pcm, ax=ax, label='Intensity Ratio')\n",
        "                    ax.set_title(f'Ratio Surface: {comp1_name} / {comp2_name}', fontsize=12)\n",
        "\n",
        "                else:\n",
        "                    ax.set_title(f'Shape mismatch: {comp1_name} vs {comp2_name}', fontsize=12)\n",
        "                    ax.text(0.5, 0.5, 'Data shapes mismatch', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n",
        "\n",
        "                combo_index += 1\n",
        "            else:\n",
        "                # Hide unused subplots\n",
        "                axes[i].set_visible(True)\n",
        "\n",
        "        fig.suptitle(f'Foul Intensity Ratio Surfaces (2015/2016 Season) - Page {fig_num + 1}', y=1.01, fontsize=18)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "elif len(competitions_to_plot) < 2:\n",
        "    print(\"Not enough competitions with intensity data to calculate ratio surfaces.\")\n"
      ],
      "metadata": {
        "id": "Dulo3iXao2QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a Gaussian Mixture Model**\n",
        "\n",
        "The next step is break down the data into similar areas for testing purposes\n",
        "\n",
        "This section utilizes a Gaussian Mixture Model (GMM) to identify data-driven zones based on the spatial distribution of fouls. GMM is a probabilistic model that assumes the data points are generated from a mixture of several Gaussian distributions. By fitting a GMM to the foul coordinates, we can cluster areas of the pitch that have similar patterns of foul intensity, creating distinct zones for further analysis."
      ],
      "metadata": {
        "id": "JK81KAChR1lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_fouls = df_concatenated2_2015_2016[df_concatenated2_2015_2016['is_foul_committed'] == 1].copy()\n",
        "geospatial_features = ['x2', 'y2']\n",
        "kde = KernelDensity(kernel='gaussian', bandwidth=3)  # adjust bandwidth\n",
        "coords = df_comp_fouls[geospatial_features].values\n",
        "kde.fit(coords)\n",
        "X_grid, Y_grid = np.meshgrid(np.linspace(0, 120, 240), np.linspace(0, 80, 160))\n",
        "grid_coords = np.vstack([X_grid.ravel(), Y_grid.ravel()]).T\n",
        "log_dens = kde.score_samples(grid_coords)\n",
        "intensity_array = np.exp(log_dens).reshape(X_grid.shape)\n",
        "# Step 1: Get coordinates of each cell\n",
        "rows, cols = np.indices(intensity_array.shape)\n",
        "coords = np.column_stack((cols.ravel(), rows.ravel()))  # shape: (n_cells, 2)\n",
        "random=0\n",
        "# Step 2: Get intensities (weights)\n",
        "weights = intensity_array.ravel()\n",
        "weights = weights / weights.sum()  # Normalize to sum to 1\n",
        "\n",
        "# Step 3: Resample points with repetition based on intensity\n",
        "N = 10000  # Total number of points to sample\n",
        "rng = np.random.default_rng(random) # Create a reproducible random number generator\n",
        "sample_indices = rng.choice(len(weights), size=N, p=weights)\n",
        "\n",
        "sampled_coords = coords[sample_indices]\n"
      ],
      "metadata": {
        "id": "HoMn7wxpzSfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find optimal breakdown**"
      ],
      "metadata": {
        "id": "oEXgz517oatI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bic = []\n",
        "for k in range(3, 16):\n",
        "    gmm = GaussianMixture(n_components=k,random_state=random).fit(sampled_coords)\n",
        "    bic.append(gmm.bic(sampled_coords))"
      ],
      "metadata": {
        "id": "jLzWQWT2zVKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the BIC for each k\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(range(3, 16), bic, marker='o')\n",
        "plt.xlabel('Number of Components (k)')\n",
        "plt.ylabel('BIC')\n",
        "plt.title('BIC vs. Number of Components')\n",
        "plt.xticks(range(3, 16))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fcRqexaxzXUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**View map**"
      ],
      "metadata": {
        "id": "amm1TwadoeMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Fit GMM\n",
        "n_components = 8  # Number of zones to learn\n",
        "gmm = GaussianMixture(n_components=n_components, random_state=random)\n",
        "gmm.fit(sampled_coords)\n",
        "\n",
        "# Step 5: Predict zone labels for full pitch\n",
        "all_labels = gmm.predict(coords)\n",
        "zone_map = all_labels.reshape(intensity_array.shape)\n",
        "\n",
        "# Step 6: Plot the resulting zones\n",
        "pitch = Pitch(pitch_color='white', line_color='black')\n",
        "fig, ax = pitch.draw(figsize=(10, 6))\n",
        "cmap = plt.get_cmap('tab10')\n",
        "\n",
        "# Visualize the zones\n",
        "im = ax.imshow(zone_map, origin='lower', extent=(0, 120, 0, 80), cmap=cmap, alpha=0.6)\n",
        "cbar = plt.colorbar(im, ax=ax, fraction=0.035)\n",
        "cbar.set_label('GMM Zone')\n",
        "\n",
        "plt.title('Data-driven Zones from GMM on Foul Intensity Map')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TX0B4oqj0KT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chosen zones**\n",
        "\n",
        "Chosen zones are selected on the basis of the generated zones with additional tactical and interpretable considerations such as the attacking and defensive boxes."
      ],
      "metadata": {
        "id": "Q86V3Q4DpnEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Define zones as before, with main and additional rectangles per zone\n",
        "zones = {\n",
        "    1: [(0, 0, 36, 36), (36, 0, 80, 80)],\n",
        "    2: [(0, 124, 36, 160), (36, 80, 80, 160)],\n",
        "    3: [(80, 0, 160, 53)],\n",
        "    4: [(80, 53, 160, 107)],\n",
        "    5: [(80, 107, 160, 160)],\n",
        "    6: [(204, 0, 240, 36), (160, 0, 204, 80)],\n",
        "    7: [(204, 124, 240, 160), (160, 80, 204, 160)],\n",
        "    8: [(0, 36, 36, 124)],\n",
        "    9: [(204, 36, 240, 124)]\n",
        "}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Pitch dimensions for plotting\n",
        "pitch_length = 240\n",
        "pitch_width = 160\n",
        "\n",
        "# Draw pitch outline\n",
        "ax.plot([0, pitch_length, pitch_length, 0, 0], [0, 0, pitch_width, pitch_width, 0], color='black')\n",
        "\n",
        "# Colors for zones (repeat if needed)\n",
        "colors = plt.cm.get_cmap('tab10', 10)\n",
        "\n",
        "for zone_id, rects in zones.items():\n",
        "    for idx, (start_col, start_row, end_col, end_row) in enumerate(rects):\n",
        "        width = end_col - start_col\n",
        "        height = end_row - start_row\n",
        "\n",
        "        rect_patch = patches.Rectangle(\n",
        "            (start_col, start_row),\n",
        "            width,\n",
        "            height,\n",
        "            linewidth=2,\n",
        "            edgecolor=colors(zone_id),\n",
        "            facecolor=colors(zone_id),\n",
        "            alpha=0.3\n",
        "        )\n",
        "        ax.add_patch(rect_patch)\n",
        "\n",
        "        # Label zones in the middle of each rectangle\n",
        "        ax.text(\n",
        "            start_col + width / 2,\n",
        "            start_row + height / 2,\n",
        "            f\"{zone_id}\" if idx == 0 else \"\",  # Label only once per zone\n",
        "            color='black',\n",
        "            fontsize=14,\n",
        "            fontweight='bold',\n",
        "            ha='center',\n",
        "            va='center'\n",
        "        )\n",
        "\n",
        "ax.set_xlim(0, 240)\n",
        "ax.set_ylim(0, 160)\n",
        "ax.set_xlabel(\"Pitch Length\")\n",
        "ax.set_ylabel(\"Pitch Width\")\n",
        "ax.set_title(\"Selected zones for analysis\")\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bAHEzhM9plxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Energy distance and permutation tests**\n",
        "\n",
        "Energy distance measures the difference between two arrays in 2d\n",
        "\n",
        "Permutations test is an iterative process. The distance is measured. THe 2 sets of datapoints get shuffled up. The new distance is measured. If the random distance is less than the true distribution it is counted as a statistical difference. This counts up for each iteration so the more times the random difference is less the higher the chance of statistical difference."
      ],
      "metadata": {
        "id": "EoMNoxLiqoVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def energy_distance_statistic(X, Y):\n",
        "    \"\"\"\n",
        "    Calculate the energy distance between two samples X and Y.\n",
        "    X and Y should be 1D or 2D numpy arrays.\n",
        "    \"\"\"\n",
        "    X = np.atleast_2d(X)\n",
        "    Y = np.atleast_2d(Y)\n",
        "\n",
        "    n, m = len(X), len(Y)\n",
        "\n",
        "    # Pairwise distances\n",
        "    XY_dist = cdist(X, Y, metric='euclidean')\n",
        "    XX_dist = cdist(X, X, metric='euclidean')\n",
        "    YY_dist = cdist(Y, Y, metric='euclidean')\n",
        "\n",
        "    term1 = (2.0 / (n * m)) * np.sum(XY_dist)\n",
        "    term2 = (1.0 / (n * n)) * np.sum(XX_dist)\n",
        "    term3 = (1.0 / (m * m)) * np.sum(YY_dist)\n",
        "\n",
        "    energy_dist = term1 - term2 - term3\n",
        "    return energy_dist\n",
        "\n",
        "def permutation_test_energy_distance(data1, data2, n_permutations=1000, random_state=None):\n",
        "    \"\"\"\n",
        "    Perform a permutation test using the energy distance statistic.\n",
        "\n",
        "    Args:\n",
        "      data1 (array-like): First sample.\n",
        "      data2 (array-like): Second sample.\n",
        "      n_permutations (int): Number of permutations.\n",
        "      random_state (int or None): Seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      observed_stat (float): Observed energy distance.\n",
        "      p_value (float): Permutation p-value.\n",
        "    \"\"\"\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    data1 = np.asarray(data1)\n",
        "    data2 = np.asarray(data2)\n",
        "\n",
        "    observed_stat = energy_distance_statistic(data1, data2)\n",
        "\n",
        "    combined = np.concatenate([data1, data2])\n",
        "    n1 = len(data1)\n",
        "\n",
        "    count = 0\n",
        "    for _ in range(n_permutations):\n",
        "        permuted = np.random.permutation(combined)\n",
        "        perm_sample1 = permuted[:n1]\n",
        "        perm_sample2 = permuted[n1:]\n",
        "        stat = energy_distance_statistic(perm_sample1, perm_sample2)\n",
        "\n",
        "        if stat >= observed_stat:\n",
        "            count += 1\n",
        "\n",
        "    p_value = count / n_permutations\n",
        "\n",
        "    return observed_stat, p_value"
      ],
      "metadata": {
        "id": "jJXBPiejpDcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zones = {\n",
        "    1: [(0, 0, 18, 18), (18, 0, 40, 40)],\n",
        "    2: [(0, 62, 18, 80), (18, 40, 40, 80)],\n",
        "    3: [(40, 0, 80, 26)],\n",
        "    4: [(40, 26, 80, 53)],\n",
        "    5: [(40, 53, 80, 80)],\n",
        "    6: [(102, 0, 120, 18), (80, 0, 102, 40)],\n",
        "    7: [(102, 62, 120, 80), (80, 40, 102, 80)],\n",
        "    8: [(0, 18, 18, 62)],\n",
        "    9: [(102, 18, 120, 62)]\n",
        "}\n",
        "# --- PART 2: Permutation Test (Zonal Comparison) ---\n",
        "# This dictionary will store raw foul coordinates per league and per zone.\n",
        "league_zone_coordinates = {}\n",
        "\n",
        "for competition in unique_competitions:\n",
        "    league_zone_coordinates[competition] = {}\n",
        "    df_comp_fouls = df_fouls[df_fouls['competition'] == competition].copy()\n",
        "    coords = df_comp_fouls[['x2', 'y2']].values # Extract (x,y) coordinates for the league\n",
        "\n",
        "    for zone_id, rects in zones.items():\n",
        "        zone_points = []\n",
        "        for (start_col, start_row, end_col, end_row) in rects:\n",
        "            # Filter points that fall within the zone's rectangle(s)\n",
        "            # Note: Assuming pitch (0,0) is bottom-left, x increases right, y increases up.\n",
        "            in_zone = (\n",
        "                (coords[:, 0] >= start_col) & (coords[:, 0] < end_col) &\n",
        "                (coords[:, 1] >= start_row) & (coords[:, 1] < end_row)\n",
        "            )\n",
        "            zone_points.append(coords[in_zone])\n",
        "\n",
        "        # Combine points from all rectangles within the zone\n",
        "        if zone_points:\n",
        "            # np.vstack combines arrays vertically if they have compatible shapes\n",
        "            league_zone_coordinates[competition][zone_id] = np.vstack(zone_points)\n",
        "        else:\n",
        "            # If no points found for a zone, store an empty array\n",
        "            league_zone_coordinates[competition][zone_id] = np.array([])\n",
        "\n",
        "# This list will store results from all zones, AFTER their per-zone correction\n",
        "all_corrected_permutation_results = []\n",
        "leagues = list(unique_competitions) # Get a list of all unique league names\n",
        "\n",
        "# Loop through each zone to perform pairwise comparisons and then apply Holm's correction\n",
        "for zone_id in sorted(zones.keys()):\n",
        "    print(f\"\\nComparing Zone {zone_id}\")\n",
        "\n",
        "    # Lists to collect p-values and their associated comparison info for the CURRENT ZONE ONLY\n",
        "    current_zone_p_values = []\n",
        "    current_zone_comparisons_info = []\n",
        "\n",
        "    # Perform all pairwise comparisons within the current zone\n",
        "    for i in range(len(leagues)):\n",
        "        for j in range(i + 1, len(leagues)): # Ensures each pair is tested only once (e.g., A vs B, not B vs A)\n",
        "            league1, league2 = leagues[i], leagues[j]\n",
        "\n",
        "            # Get data for the two leagues in the current zone\n",
        "            # .get() with a default empty array handles cases where a league might not have data for a specific zone\n",
        "            data1 = league_zone_coordinates[league1].get(zone_id, np.array([]))\n",
        "            data2 = league_zone_coordinates[league2].get(zone_id, np.array([]))\n",
        "\n",
        "            # Skip comparison if either league has too few data points in this zone\n",
        "            # Energy distance requires at least 2 points for calculation\n",
        "            if len(data1) < 2 or len(data2) < 2:\n",
        "                print(f\"  Skipping {league1} vs {league2} in Zone {zone_id}: insufficient data (needs >= 2 points).\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Testing {league1} vs {league2}\")\n",
        "            # Run the permutation test for this specific pair in this zone\n",
        "            observed_diff, p_value = permutation_test_energy_distance(data1, data2, n_permutations=1000)\n",
        "\n",
        "            # Collect the raw p-value and all relevant comparison details\n",
        "            current_zone_p_values.append(p_value)\n",
        "            current_zone_comparisons_info.append({\n",
        "                'comparison': f\"{league1} vs {league2}\",\n",
        "                'zone': zone_id,\n",
        "                'observed_diff': observed_diff,\n",
        "                'p_value': p_value # Store original p-value before correction\n",
        "            })\n",
        "\n",
        "    # --- Apply Holm Correction PER ZONE ---\n",
        "    if current_zone_p_values: # Only proceed if there were valid comparisons in this zone\n",
        "        p_values_array = np.array(current_zone_p_values)\n",
        "\n",
        "        # Perform Holm-Bonferroni correction\n",
        "        reject_zone, pvals_corrected_zone, _, _ = multipletests(p_values_array, method='holm')\n",
        "\n",
        "        # Attach the corrected p-values and significance flags to the comparison info\n",
        "        for idx, info in enumerate(current_zone_comparisons_info):\n",
        "            info['p_value_corrected'] = pvals_corrected_zone[idx]\n",
        "            info['significant (corrected)'] = reject_zone[idx]\n",
        "            # Add these results to the overall list of all corrected results\n",
        "            all_corrected_permutation_results.append(info)\n",
        "    else:\n",
        "        print(f\"No valid comparisons were made for Zone {zone_id} to apply correction.\")\n",
        "\n",
        "# === Final Results Display for Per-Zone Corrected P-values ===\n",
        "# Convert the list of dictionaries into a Pandas DataFrame for easy viewing\n",
        "df_permutation_results_corrected_per_zone = pd.DataFrame(all_corrected_permutation_results)\n",
        "\n",
        "if not df_permutation_results_corrected_per_zone.empty:\n",
        "    print(\"\\nPermutation Test Results (Comparing Foul Locations per Zone - Holm-corrected PER ZONE):\")\n",
        "    # Display the full DataFrame with original and corrected p-values\n",
        "    print(df_permutation_results_corrected_per_zone)\n",
        "\n",
        "    # Filter for comparisons that are significant after correction\n",
        "    significant_comparisons_per_zone = df_permutation_results_corrected_per_zone[df_permutation_results_corrected_per_zone['significant (corrected)']]\n",
        "\n",
        "    print(\"\\nSignificant differences (Holm-corrected p < 0.05 PER ZONE):\")\n",
        "    if not significant_comparisons_per_zone.empty:\n",
        "        # Display only the significant comparisons\n",
        "        print(significant_comparisons_per_zone)\n",
        "    else:\n",
        "        print(\"No significant differences found after per-zone correction.\")\n",
        "else:\n",
        "    print(\"No pairs of competitions with data to compare across all zones.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F2JTG7sSRiLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_permutation_results_corrected_per_zone['significant']=df_permutation_results_corrected_per_zone['p_value']<0.05\n",
        "df_permutation_results_corrected_per_zone"
      ],
      "metadata": {
        "id": "wauX5baAVkww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**plot results by zone**"
      ],
      "metadata": {
        "id": "BZgpWFhNt6CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zones = {\n",
        "    1: [(0, 0, 36, 36), (36, 0, 80, 80)],\n",
        "    2: [(0, 124, 36, 160), (36, 80, 80, 160)],\n",
        "    3: [(80, 0, 160, 53)],\n",
        "    4: [(80, 53, 160, 107)],\n",
        "    5: [(80, 107, 160, 160)],\n",
        "    6: [(204, 0, 240, 36), (160, 0, 204, 80)],\n",
        "    7: [(204, 124, 240, 160), (160, 80, 204, 160)],\n",
        "    8: [(0, 36, 36, 124)],\n",
        "    9: [(204, 36, 240, 124)]\n",
        "}\n",
        "\n",
        "field_width, field_height = 240, 160\n",
        "\n",
        "df_permutation_results_corrected_per_zone['zone'] = df_permutation_results_corrected_per_zone['zone'].astype(int)\n",
        "comparisons = df_permutation_results_corrected_per_zone['comparison'].unique()\n",
        "\n",
        "n = len(comparisons)\n",
        "cols = 2  # number of columns for subplot grid\n",
        "rows = (n + cols - 1) // cols  # ceiling division for rows\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*6, rows*5))\n",
        "axes = axes.flatten()  # flatten in case of multiple rows\n",
        "cmap = plt.get_cmap('Greys')   # Greyscale colormap\n",
        "norm = plt.Normalize(vmin=0, vmax=1)  # 0 = black, 1 = white\n",
        "for i, comparison in enumerate(comparisons):\n",
        "    df_comp = df_permutation_results_corrected_per_zone[df_permutation_results_corrected_per_zone['comparison'] == comparison]\n",
        "    field = np.ones((field_height, field_width))  # 1 = not significant by default\n",
        "\n",
        "    for zone_id, rects in zones.items():\n",
        "        row = df_comp[df_comp['zone'] == zone_id]\n",
        "\n",
        "        if row.empty:\n",
        "            is_sig = False\n",
        "        else:\n",
        "            is_sig = row['significant'].any()\n",
        "\n",
        "        value = 0 if is_sig else 1  # 0 = significant (black), 1 = not significant (white)\n",
        "\n",
        "        for (x0, y0, x1, y1) in rects:\n",
        "            field[y0:y1, x0:x1] = value\n",
        "    ax = axes[i]\n",
        "    im = ax.imshow(field, cmap=cmap, origin='upper', norm=norm)\n",
        "    ax.set_title(f\"Significance Map\\n{comparison}\", fontsize=10)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlim(0, field_width)\n",
        "    ax.set_ylim(field_height, 0)\n",
        "\n",
        "    # Draw zone outlines\n",
        "    for rects in zones.values():\n",
        "        for (x0, y0, x1, y1) in rects:\n",
        "            rect = plt.Rectangle((x0, y0), x1 - x0, y1 - y0,\n",
        "                                 edgecolor='black', facecolor='none', linewidth=0.5)\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    # Add individual colorbar for each subplot\n",
        "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])\n",
        "    fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.01,\n",
        "                 label='0 = significant, 1 = not significant')\n",
        "\n",
        "# Remove unused axes\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wdOZ7cymbJ5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zones = {\n",
        "    1: [(0, 0, 36, 36), (36, 0, 80, 80)],\n",
        "    2: [(0, 124, 36, 160), (36, 80, 80, 160)],\n",
        "    3: [(80, 0, 160, 53)],\n",
        "    4: [(80, 53, 160, 107)],\n",
        "    5: [(80, 107, 160, 160)],\n",
        "    6: [(204, 0, 240, 36), (160, 0, 204, 80)],\n",
        "    7: [(204, 124, 240, 160), (160, 80, 204, 160)],\n",
        "    8: [(0, 36, 36, 124)],\n",
        "    9: [(204, 36, 240, 124)]\n",
        "}\n",
        "\n",
        "field_width, field_height = 240, 160\n",
        "\n",
        "df_permutation_results_corrected_per_zone['zone'] = df_permutation_results_corrected_per_zone['zone'].astype(int)\n",
        "comparisons = df_permutation_results_corrected_per_zone['comparison'].unique()\n",
        "\n",
        "n = len(comparisons)\n",
        "cols = 2\n",
        "rows = (n + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols*6, rows*5))\n",
        "axes = axes.flatten()\n",
        "cmap = plt.get_cmap('Greys_r')\n",
        "norm = Normalize(vmin=0, vmax=1.0)  # <--- Use a linear scale from 0 to 1\n",
        "\n",
        "for i, comparison in enumerate(comparisons):\n",
        "    df_comp = df_permutation_results_corrected_per_zone[df_permutation_results_corrected_per_zone['comparison'] == comparison]\n",
        "    field = np.ones((field_height, field_width))\n",
        "\n",
        "    for zone_id, rects in zones.items():\n",
        "        row = df_comp[df_comp['zone'] == zone_id]\n",
        "\n",
        "        if row.empty or row['p_value'].iloc[0] == np.nan:\n",
        "            value = 1.0\n",
        "        else:\n",
        "            value = row['p_value'].iloc[0]\n",
        "\n",
        "        for (x0, y0, x1, y1) in rects:\n",
        "            field[y0:y1, x0:x1] = value\n",
        "\n",
        "    ax = axes[i]\n",
        "    im = ax.imshow(field, cmap=cmap, origin='upper', norm=norm)\n",
        "    ax.set_title(f\"P-value Map\\n{comparison}\", fontsize=10)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xlim(0, field_width)\n",
        "    ax.set_ylim(field_height, 0)\n",
        "\n",
        "    for rects in zones.values():\n",
        "        for (x0, y0, x1, y1) in rects:\n",
        "            rect = plt.Rectangle((x0, y0), x1 - x0, y1 - y0,\n",
        "                                 edgecolor='black', facecolor='none', linewidth=0.5)\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
        "    sm.set_array([])\n",
        "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.01)\n",
        "    cbar.set_label('p-value')\n",
        "\n",
        "for j in range(i+1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qEPUx8buMa6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stouffers z method test**\n",
        "\n",
        "Calculate the foul weights and combine by compared competition to determine the value is each statistical zone. Then apply Stouffers Z method and adjust by Holm.\n"
      ],
      "metadata": {
        "id": "tRdh0z2fr-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zones_halved = {\n",
        "    1: [(0, 0, 18, 18), (18, 0, 40, 40)],\n",
        "    2: [(0, 62, 18, 80), (18, 40, 40, 80)],\n",
        "    3: [(40, 0, 80, 26)],\n",
        "    4: [(40, 26, 80, 53)],\n",
        "    5: [(40, 53, 80, 80)],\n",
        "    6: [(102, 0, 120, 18), (80, 0, 102, 40)],\n",
        "    7: [(102, 62, 120, 80), (80, 40, 102, 80)],\n",
        "    8: [(0, 18, 18, 62)],\n",
        "    9: [(102, 18, 120, 62)]\n",
        "}\n",
        "\n",
        "def assign_zone(row, zones):\n",
        "    x, y = row['x2'], row['y2']\n",
        "    for zone_id, rects in zones.items():\n",
        "        for (x0, y0, x1, y1) in rects:\n",
        "            # Scale the pitch coordinates (0-120, 0-80) to zone coordinates (0-240, 0-160)\n",
        "            scaled_x = x\n",
        "            scaled_y = y\n",
        "\n",
        "            if x0 <= scaled_x < x1 and y0 <= scaled_y < y1:\n",
        "                return zone_id\n",
        "    return None # Return None if the foul is outside all defined zones\n",
        "\n",
        "df_fouls['zone_id'] = df_fouls.apply(lambda row: assign_zone(row, zones_halved), axis=1)\n",
        "\n",
        "# Filter out rows where zone_id could not be assigned\n",
        "df_fouls_zoned = df_fouls.dropna(subset=['zone_id']).copy()\n",
        "\n",
        "# Count fouls per zone by competition\n",
        "foul_counts_by_zone_comp = df_fouls_zoned.groupby(['competition', 'zone_id']).size().reset_index(name='foul_count')\n",
        "\n",
        "print(\"Number of fouls per zone by competition:\")\n",
        "foul_counts_by_zone_comp"
      ],
      "metadata": {
        "id": "4lmYEsN6b9ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "competition_combinations = [\n",
        "    ('Spain - La Liga', 'England - Premier League'),\n",
        "    ('Spain - La Liga', 'France - Ligue 1'),\n",
        "    ('Spain - La Liga', 'Italy - Serie A'),\n",
        "    ( 'Germany - 1. Bundesliga','Spain - La Liga'),\n",
        "    ('France - Ligue 1','England - Premier League'),\n",
        "    ('England - Premier League', 'Italy - Serie A'),\n",
        "    ('Germany - 1. Bundesliga','England - Premier League'),\n",
        "    ('France - Ligue 1', 'Italy - Serie A'),\n",
        "    ('Germany - 1. Bundesliga','France - Ligue 1'),\n",
        "    ('Germany - 1. Bundesliga','Italy - Serie A'),\n",
        "]\n",
        "\n",
        "combined_foul_counts = []\n",
        "\n",
        "# Iterate through each desired combination\n",
        "for comp1, comp2 in competition_combinations:\n",
        "    # Filter foul counts for the two competitions in the current combination\n",
        "    df_comp1 = foul_counts_by_zone_comp[foul_counts_by_zone_comp['competition'] == comp1].copy()\n",
        "    df_comp2 = foul_counts_by_zone_comp[foul_counts_by_zone_comp['competition'] == comp2].copy()\n",
        "\n",
        "    # Merge the two dataframes on zone_id to align counts for each zone\n",
        "    # Use outer merge to keep all zones, even if a zone has zero fouls in one competition\n",
        "    df_combined = pd.merge(df_comp1, df_comp2, on='zone_id', how='outer', suffixes=(f'_{comp1}', f'_{comp2}')).fillna(0)\n",
        "\n",
        "    # Calculate the sum of foul counts for each zone in this combination\n",
        "    df_combined['total_foul_count'] = df_combined[f'foul_count_{comp1}'] + df_combined[f'foul_count_{comp2}']\n",
        "\n",
        "    # Add the comparison name\n",
        "    df_combined['comparison'] = f'{comp1} vs {comp2}'\n",
        "\n",
        "    # Select and reorder columns for the result\n",
        "    result_cols = ['comparison', 'zone_id', 'total_foul_count']\n",
        "    df_combined_subset = df_combined[result_cols]\n",
        "\n",
        "    combined_foul_counts.append(df_combined_subset)\n",
        "\n",
        "# Concatenate all combined results into a single DataFrame\n",
        "df_combined_foul_counts = pd.concat(combined_foul_counts, ignore_index=True)\n",
        "\n",
        "print(\"Combined foul counts by zone_id for unique competition combinations:\")\n",
        "df_combined_foul_counts\n"
      ],
      "metadata": {
        "id": "3ZzlNOK1cYsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def stouffers_z_method_weighted(p_values, weights):\n",
        "    \"\"\"\n",
        "    Applies weighted Stouffer's Z-score method to combine p-values.\n",
        "\n",
        "    Args:\n",
        "        p_values (array-like): List or array of p-values.\n",
        "        weights (array-like): Corresponding weights (e.g., foul counts) for each p-value.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (combined_z, combined_p)\n",
        "    \"\"\"\n",
        "    p_values = np.clip(p_values, 1e-15, 1 - 1e-15)  # Avoid extremes\n",
        "    z_scores = norm.isf(p_values)  # Convert to Z-scores (one-sided test)\n",
        "\n",
        "    weights = np.array(weights)\n",
        "    weighted_z = np.sum(weights * z_scores) / np.sqrt(np.sum(weights ** 2))\n",
        "    combined_p = norm.sf(weighted_z)  # One-sided p-value\n",
        "\n",
        "    return weighted_z, combined_p\n",
        "\n",
        "# Merge the two dataframes on 'comparison' and 'zone'\n",
        "df_merged_stouffer = pd.merge(\n",
        "    df_permutation_results_corrected_per_zone[['comparison', 'zone', 'p_value','p_value_corrected']],\n",
        "    df_combined_foul_counts[['comparison', 'zone_id', 'total_foul_count']],\n",
        "    left_on=['comparison', 'zone'],\n",
        "    right_on=['comparison', 'zone_id'],\n",
        "    how='inner' # Use inner merge to only keep zones present in both dataframes\n",
        ")\n",
        "\n",
        "# Group by comparison and apply Stouffer's method across zones for each comparison\n",
        "stouffer_results = []\n",
        "for comparison, group in df_merged_stouffer.groupby('comparison'):\n",
        "    p_values_for_stouffer = group['p_value'].values\n",
        "    weights = group['total_foul_count'].values\n",
        "    print(weights)\n",
        "    if len(p_values_for_stouffer) > 0:\n",
        "        combined_z, combined_p = stouffers_z_method_weighted(p_values_for_stouffer, weights)\n",
        "\n",
        "        stouffer_results.append({\n",
        "            'comparison': comparison,\n",
        "            'stouffer_combined_z': combined_z,\n",
        "            'stouffer_combined_p': combined_p,\n",
        "            'total_fouls_in_comparison': weights.sum()\n",
        "        })\n",
        "\n",
        "df_stouffer_combined = pd.DataFrame(stouffer_results)\n",
        "\n",
        "# Optional: Adjust the combined p-values if you are doing multiple Stouffer's tests\n",
        "if not df_stouffer_combined.empty:\n",
        "    combined_p_values = df_stouffer_combined['stouffer_combined_p'].values\n",
        "    reject, pvals_corrected_stouffer, _, _ = multipletests(combined_p_values, method='holm') # or 'fdr_bh'\n",
        "\n",
        "    df_stouffer_combined['stouffer_p_corrected'] = pvals_corrected_stouffer\n",
        "    df_stouffer_combined['stouffer_significant'] = reject\n",
        "\n",
        "print(\"\\nStouffer's Z Method Results (Combined p-values across zones per comparison):\")\n",
        "df_stouffer_combined"
      ],
      "metadata": {
        "id": "qxYHN7kwcGxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}